# Introduzione

## Inteligenza VS Inteligenza Artificiale
- **Intelligenza**: Complesso di facoltÃ  psichiche e mentali che consentono allâ€™uomo di pensare, comprendere o spiegare i fattio le azioni, elaborare modelli astratti della realtÃ , intendere e farsi intendere dagli altri, giudicare, e lo rendono insieme capace di adattarsi a situazioni nuove e di modificare la situazione stessa quando questa presenta ostacoli allâ€™adattamento.

- **Intelligenza artificiale**: Riproduzione parziale dellâ€™attivitÃ 
intellettuale propria dellâ€™uomo (con particolare riguardo ai
processi di apprendimento, di riconoscimento, di scelta)
realizzata o attraverso lâ€™elaborazione di modelli ideali, o,
concretamente, con la messa a punto di macchine che
utilizzano per lo piÃ¹ a tale fine elaboratori elettronici.
Pensare, comprendere, elaborare â†’ Ragionare

## Ragionamento Deduttivo

Nel **Ragionamento Deduttivo** (o ***Sillogismo***, Aristotele) la veritÃ  delle premesse, il **Caso Generale**, garantisce la veritÃ  della conclusione, il **Caso Particolare**.

REGOLA (C â†’ R): Tutti gli uomini sono mortali

CASO (C1): Socrate Ã¨ un uomo

quindi

RISULTATO (R1): Socrate Ã¨ mortale

Il **Ragionamento Deduttivo** Ã¨ il fondamento di gran parte delle **Dimostrazioni** e **Teoremi** , ma ***non ci permette di scoprire o prevedere nuovi fatti***.

## Ragionamento Induttivo

Nel **Ragionamento Induttivo**, le **Premesse**, il **Caso Particolare**, forniscono unâ€™**evidenza** piÃ¹ o meno forte a sostegno della **conclusione**, il **Caso Generale**, ma ***non ne garantiscono necessariamente la veritÃ ***.

Il **Ragionamento Induttivo** Ã¨ quindi un **Ragionamento Probabilistico**, le cui conclusioni dipendono dal **Grado di ProbabilitÃ ** delle informazioni contenute nelle **premesse**.

CASO (C1): Socrate era un uomo

RISULTATO (R1): Socrate morÃ¬

quindi

REGOLA (C â†’ R): Tutti gli uomini sono mortali

### Da rivedere
---

La forma piÃ¹ comune di ragionamento induttivo Ã¨ la
generalizzazione, con cui otteniamo informazioni su un gruppo di
cose, persone, eventi, oggetti e cosÃ¬ via, esaminando una porzione
â€“ o campione â€“ di quel gruppo.

**Ragionamento per Analogia**, che consiste nel trarre conclusioni su qualcosa in base alle sue somiglianze con qualcosâ€™altro.
Usato nel ***Machine Learning***

Questo permette agli esseri umani di:
- utilizzare metafore
- -astrarre concetti Â«portandoliÂ» da un domino allâ€™altro
- essere creativi

## Ragionamento Abduttivo

Anche in questo caso il ragionamento Ã¨ probabilistico, ma invece di generalizzare ci si muove Â«lateralmenteÂ», ipotizzando che unâ€™implicazione valga anche al contrario.

REGOLA (C â†’ R): Tutti gli uomini sono mortali

RISULTATO (R1): Socrate morÃ¬

quindi

CASO (C1): Socrate era un uomo

induzione per scienziati, lâ€™abduzione per investigatoriâ€¦

Ad Esempio:
Ragionamento di Sherlock Holmes e dr. House (cui interessa scoprire il caso in situazione di incertezza e non la regola generale).

## Inteligenza Artificiale e Machine Learning

Ascolta audio

---

## Machine Learning

Un **Modello** di **Machine Learning** :

***â€œImpara dagli esempi a migliorare le proprie prestazioni per la gestione di nuovi dati provenienti dalla stessa sorgenteâ€*** (Mickey 91).

![alt text](image.png)

## PerchÃ© Machine Learning ?

- Consente di **gestire la complessitÃ ** di applicazioni reali, talvolta troppo complesse per poter essere modellate efficacemente.

- **Apprendere il comportamento** desiderato dai dati/esempi forniti, semplifica lo sviluppo di applicazioni.

- Rende possibile **esplorare** e **comprendere** i **dati** (***Mining***) senza la necessitÃ  di programmazione esplicita.

- **Addestramento end-to-end** (es. Guida automatica veicolo).

- **Deep Learning** e **Generative AI**

![alt text](image-1.png)

## Intelligenza Artificiale e â€œforza brutaâ€

***Brute-Force***: in alcuni domini applicativi un calcolatore Ã¨ in grado di risolvere problemi in modo ottimo semplicemente **enumerando** e **valutando** tutte le **possibili alternative**.

Nella maggior parte dei casi perÃ² la valutazione esaustiva di tutte le possibili soluzioni **non Ã¨ computazionalmente gestibile**, e si usano tecniche di ricerca che utilizzano **euristici** per ridurre il numero di casi da valutare.

Talvolta si utilizza il termine ***Weak AI*** per caratterizzare **sistemi capaci di risolvere problemi complessi senza perÃ² capacitÃ  di ragionamento e comprensione**.

---

# Fondamenti

## Dati e Pattern

I **Dati** sono un **elemento fondamentale** del **Machine Learning**, dove il comportamento dei **Modelli** non Ã¨ pre-programmato ma **appreso**.

Un **Campione di Dati** nel **Dominio di Interesse** Ã¨ definito ***Data-point***.

Utilizzeremo spesso come **sinonimo** di ***Data-Point*** il termine **Pattern**.

## Tipi di Pattern

### Numerici

Valori associati a **caratteristiche misurabili** o conteggi.

Tipicamente **continui** e **soggetti a ordinamento**, rappresentabili naturalmente come **vettori numerici** nello spazio multidimensionale.

Lâ€™**estrazione di caratteristiche** da segnali produce **vettori numerici** detti anche ***Feature Vectors***.

### Categorici
Valori associati a **caratteristiche qualitative** e alla **presenza o assenza di una caratteristica**.

Naturalmente gestiti da **sistemi a regole** e **alberi di classificazione**.

Con tecniche di **encoding** o **embedding** Ã¨ possibile **mapparli su numeri**.

## Sequenze e altri dati strutturati

Le **Sequenze** sono **Pattern sequenziali** con **relazioni spaziali** o **temporali**.

La **posizione nella sequenza** e le **relazioni con predecessori** e **successori** sono **importanti**.

## Dati Tabulari

In molte applicazioni aziendali, i **dati** sono organizzati in una **tabella**, nelle cui **colonne** troviamo gli **attributi** (*features*) e nelle **righe** i **record** (*data point*).

Le **colonne** possono avere formato **numerico** o **categorico**, sono **eterogenee**.

I **dati** possono essere **incompleti** e **fortemente sbilanciati**.

## Encoding

***One-hot Encoding***: si rimuove il campo e al suo posto si aggiungono tanti campi quanti sono i valori distinti.

***Ordinal encoding***: si trasforma il campo originale in campo numerico associando ai materiali dei valori ordinali.

## Classificazione

**Classificazione**: assegnare una **classe** a un **pattern**.

Necessario apprendere una **funzione** capace di eseguire il **mapping dallo spazio dei pattern allo spazio delle classi**.

Nel caso di 2 sole classi si usa il termine ***binary classification***, con piÃ¹ di due classi ***multi-class classification***.

**Classe**: insieme di **pattern aventi proprietÃ  comuni**.

## Regressione

**Regressione**: assegnare un **valore continuo** a un **pattern**, utile per la **predizione di valori continui**.

Risolvere un **problema di regressione** corrisponde ad **apprendere una funzione**approssimante delle coppie Â«input,outputÂ» date.

### Clustering

**Clustering**: **individuare gruppi**, detti **cluster**, di **pattern con caratteristiche simili**.

Le **classi** del problema **non sono note** e i **pattern non etichettati**, la natura non supervisionata del problema lo rende piÃ¹ complesso della classificazione.

## Riduzione DimensionalitÃ 

**Riduzione di dimensionalitÃ **: ridurre il numero di **dimensioni** dei **pattern in input**.

Lâ€™**operazione** comporta una **perdita di informazione**, bisogna evitare di perdere **dati importaniti**.

## Feature Engineering

Il successo di molte **applicazioni di machine learning** dipende dallâ€™**efficacia di rappresentazione dei pattern in termini di features**.

La **definizione di features ad-hoc** per le diverse applicazioni prende il nome di ***feature engineering***.

## Modelli Discriminativi vs Generativi

I **modelli discriminativi** (classificatori) hanno lâ€™obiettivo **diassegnare un nuovo datapoint a una classe**.

La cosa importante Ã¨ apprendere il **decision boundary che separa le classi**.

I **modelli generativi** apprendono (esplicitamente/implicitamente) la **distribuzione probabilistica degli esempi** usati per il loro addestramento.

Dopo lâ€™addestramento, possono:
- **generare nuovi dati sintetici** a partire da numeri random
- **modificare** o **trasformare lâ€™input** fornito
- **classificare lâ€™input** comparando le probabilitÃ  che sia generato dalle diverse classi

## Apprendimento

**Supervisionato** (Supervised): sono **note le classi dei pattern** utilizzati per lâ€™**addestramento**, il **training set Ã¨ etichettato**.

**Non Supervisionato** (Unsupervised): **non sono note le classi dei pattern** utilizzati per lâ€™**addestramento**, il **training set non Ã¨ etichettato**.

**Semi-Supervisionato** (Semi-Supervised): il **training set Ã¨ etichettato parzialmente**,
la **distribuzione dei pattern non etichettati** puÃ² aiutare a **ottimizzare la regola di classificazione**.

## Batch, Incrementale, Naturale

**Batch**: lâ€™addestramento Ã¨ effettuato una sola volta su un training set dato. Una volta terminato il training, il sistema passa in Â«working modeÂ» e non Ã¨ in grado di apprendere ulteriormente.

**Incrementale**: a seguito dellâ€™addestramento iniziale, sono possibili ulteriori sessioni di addestramento.

**Scenari**: Sequenze di Batch, Unsupervised Tuning. Catastrofic Forgetting (il sistema dimentica quello che ha appreso in precedenza).

**Naturale**: Addestramento continuo (per tutta la vita). Addestramento attivo in working mode. Coesistenza di approccio supervisionato e non supervisionato.

## Reinforcement Learning (RL)

Lâ€™obiettivo Ã¨ **apprendere un comportamento ottimale** a partire dalle **esperienze passate**.

Un **Agente** esegue **azioni** che **modificano lâ€™ambiente**, provocando passaggi da uno stato allâ€™altro.

Quando lâ€™**Agente** ottiene **risultati positivi** riceve una **ricompensa** (reward) che perÃ² puÃ² essere temporalmente ritardata rispetto allâ€™azione, o alla sequenza di azioni, che lâ€™hanno determinata.

Obiettivo Ã¨ apprendere lâ€™**Azione Ottimale** in ciascun stato, in
modo da massimizzare la somma dei reward ottenuti nel lungo
periodo.

![alt text](image-2.png)

## Parametri e Funzione Obiettivo
Il comportamento di un **modello** $M$ di **machine learning** Ã¨ regolato da un **set di parametri** $Î˜$, per rendere esplicita questa dipendenza indichiamo il modello come M(Î˜).

Lâ€™apprendimento consiste nel **determinare il valore ottimo** $Î˜^âˆ—$ di questi **parametri**.

Dato un **training set** $ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘›$ e un **insieme di parametri**, la **funzione obiettivo** $ğ‘“(ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘›, ğ‘€(Î˜))$ puÃ² indicare:

- Lâ€™**OttimalitÃ  della Soluzione** (da massimizzare).
$$Î˜^âˆ— = ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥_Î˜ ğ‘“(ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘›, ğ‘€(Î˜))$$
- Lâ€™**Errore** o **Perdita** (loss-function) da minimizzare.
$$Î˜^âˆ— = ğ‘ğ‘Ÿğ‘”ğ‘šğ‘–ğ‘›_Î˜ ğ‘“(ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘›, ğ‘€(Î˜))$$

La **Funzione Obbiettivo** puÃ² essere ottimizzata:
- **Esplicitamente**, con metodi che operano a partire dalla sua **definizione matematica**.
- **Implicitamente**, utilizzando **euristici** che modificano i **parametri** in modo coerente con $ğ‘“$.

## Iperparametri

Stabilito il modello da utilizzare, **prima dellâ€™apprendimento** vero e proprio, deve essere definito il valore degli **Iperparametri**.

Gli **iperparametri** $ğ»$ definiscono i **dettagli architetturali del modello** e della corrispondente procedura di training, per rendere esplicita anche questa dipendenza utilizziamo $ğ‘€(ğ», Î˜)$.

## Training, Validation, Test

Il **Training Set** (Train) Ã¨ lâ€™**insieme di pattern** su cui **addestrare il modello**, trovando il valore ottimo per i parametri $Î˜$.

Il **Validation Set** (Valid) Ã¨ lâ€™**insieme di pattern** su cui **tarare gli iperparametri** $H$ (ciclo esterno).

Il **Test Set** (Test) Ã¨ lâ€™**insieme di pattern** su cui **valutare le prestazioni finali**.

## K-fold Cross-Validation

Una scelta piÃ¹ robusta degli **iperparametri** si ottiene con la procedura di ***k-fold Cross-Validation***.

![alt text](image-3.png)

Per ogni **combinazione di iperparametri** $H_i$ che si vuole valutare:
- Si esegue 5 volte il **training** scegliendo uno dei **fold** come **Valid** e i 4 rimanenti come **Train**.
- Si calcola lâ€™**accuratezza** o $avg\_acc_i$ come **media/mediana** delle 5 **accuratezze sui rispettivi Valid**.

Si sceglie la **combinazione di iperparametri** con **migliore** $avg\_acc_i$.

Scelti gli **iperparametri** ottimali si **riaddestra il modello** su tutto il **training set** (5 fold) e, solo a questo punto, si verificano le **prestazioni sul test set**.
